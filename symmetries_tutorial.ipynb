{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/royforestano/Deep_Learning_Symmetries/blob/main/symmetries_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Symmetries and Their Lie Groups, Algebras, and Subalgebras from First Principles - Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Roy Forestano\n",
    "\n",
    "Date of Completion: 13 January 2023\n",
    "\n",
    "Connected to the paper on: Deep Learning Symmetries and Their Lie Groups, Algebras, and Subalgebras from First Principles (arXiv:2301.05638: https://arxiv.org/abs/2301.05638)\n",
    "\n",
    "In this notebook, I build a neural network which takes in a random state of matrices and structure constants and alters them to reproduce the generators and structure constants of a given non-abelian group [ here SO(3) ] with dimension $N$ given a data set of the same dimension. The model takes in an array of the desired number of generators $N_{g}$ as $N \\times N$ matrices and an array of the structure constants with shape $N_{brackets} \\times N_{g}$. One part of the model then loops over each of the generators applying a sequential layer to each. The second part is one sequential layer over the structure constant array. The model modifies these arrays to produce the desired generators and structure constants with an interconnected loss function between generators and structure constants to satisy the necessary conditions.\n",
    "\n",
    "Aside: This notebook only computes the structure constants for $N < 6$ due to runtime issues. It will still run as desired for higher than five dimensions, but will only be finding the generators and not the structure constants. This model runs more efficiently with less epochs for lower dimensions, however, if you would like to scale the model to find the structure constants for higher dimesnions, construct a module list for the structure constants (as is being done for the generators) in the model, which will find the structure constants row by row rather than the entire matrix all at once. The number of epochs will need to be increased to arrive at the same loss, but fortunately, the model will run for large dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Torch.norm: https://pytorch.org/docs/stable/generated/torch.norm.html\n",
    "2. Rot in 4D: https://en.wikipedia.org/wiki/Rotations_in_4-dimensional_Euclidean_space\n",
    "3. Matrix Norm: https://en.wikipedia.org/wiki/Matrix_norm\n",
    "4. Stack lie: https://math.stackexchange.com/questions/1284164/structure-constants-for-and-the-adjoint-representation-and-meaning-in-sl2-f?rq=1\n",
    "5. $L^2$ Norm: https://mathworld.wolfram.com/L2-Norm.html\n",
    "6. Parameters: https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac\n",
    "7. Another way to transpose, (tensor).T or torch.t(): https://pytorch.org/docs/stable/generated/torch.t.html\n",
    "8. Complex Eigenvalues: https://math.stackexchange.com/questions/1546104/complex-eigenvalues-of-a-rotation-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = 'sans-serif'\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7ad3565490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n       = 300 # sample size\n",
    "n_dim   = 3   # dimension\n",
    "n_gen   = 1   # n_gen_full = int(n_dim*(n_dim-1)/2) formula for full algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceate n number of n-dim vectors\n",
    "data    = torch.tensor(np.random.randn(n,n_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the possible oracles, $\\phi(x)$, to be used in the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_dim==2:\n",
    "    def oracle_squeeze(data):\n",
    "        return (data[:,0]*data[:,1]).reshape(data.shape[0],1)\n",
    "    \n",
    "    def oracle_piecewise_linear(data):\n",
    "        a = data[:,0]\n",
    "        return np.where(a >= 0, a, -data[:,1])\n",
    "    \n",
    "    def oracle_manhattan(data):\n",
    "        return torch.abs(data[:,0])+torch.abs(data[:,1])\n",
    "\n",
    "def oracle_norm(data): # L^2 Norm (includes imaginary) on X: sqrt(sum(|x_i|^2))\n",
    "    return torch.norm(data,dim=1)\n",
    "                \n",
    "if n_dim==4:\n",
    "    def oracle_lorentz(data):\n",
    "        return (data[:,0].reshape(data.shape[0],1))**2 \\\n",
    "                - (data[:,1].reshape(data.shape[0],1))**2 \\\n",
    "                - (data[:,2].reshape(data.shape[0],1))**2 \\\n",
    "                - (data[:,3].reshape(data.shape[0],1))**2  \n",
    "#- torch.sum( (data[:,1:].reshape(data.shape[0],3))**2,dim=1) does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an oracle and epsilon $\\epsilon$ for the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n",
      "tensor([2.0567, 3.0764, 0.9676, 1.5180, 0.8894, 1.5446])\n"
     ]
    }
   ],
   "source": [
    "oracle = oracle_norm\n",
    "eps   = 1e-3\n",
    "# this y is not used below\n",
    "y = oracle(data)\n",
    "print(y.shape)\n",
    "print(y[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Lie Bracket (or Commutator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bracket(M,N):\n",
    "    return M@N - N@M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Initial Matrices to be Altered into Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_matrices = torch.tensor(np.array([ np.random.randn(n_dim,n_dim) for i in range(n_gen) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_matrices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Initial Structure Constant Matrix to be Altered into the Structure Constants for each Unique Non-Trivial Bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_com = int(n_gen*(n_gen-1)/2) # N_g choose 2 of these\n",
    "initialize_struc_const = torch.tensor(np.random.randn(n_com,n_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_struc_const.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class find_generators(nn.Module):\n",
    "    def __init__(self,n_dim,n_gen,n_com):\n",
    "        super(find_generators,self).__init__() \n",
    "       \n",
    "        G = [ nn.Sequential( nn.Linear(in_features = n_dim*n_dim, out_features = n_dim*n_dim, bias = True),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Linear(in_features = n_dim*n_dim, out_features = n_dim*n_dim, bias = True),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Linear(in_features = n_dim*n_dim, out_features = n_dim*n_dim, bias = True) )  for _ in range(n_gen)]\n",
    "        \n",
    "        \n",
    "        self.gens = nn.ModuleList(G)\n",
    "        \n",
    "        if n_dim<6:\n",
    "            self.struct_const = nn.Sequential( nn.Linear(in_features = n_gen*n_com, out_features = n_gen*n_com),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(in_features = n_gen*n_com, out_features = n_gen*n_com),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(in_features = n_gen*n_com, out_features = n_gen*n_com) )\n",
    "        \n",
    "        self.n_gen = n_gen\n",
    "        self.n_dim = n_dim\n",
    "        self.n_com = n_com\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        generators = []\n",
    "        for i in range(self.n_gen):\n",
    "            generators.append( ( self.gens[i](x[i].flatten()) ).reshape(self.n_dim,self.n_dim)  )\n",
    "            \n",
    "        if self.n_dim<6:\n",
    "            structure_constants =  self.struct_const(c.flatten()).reshape(self.n_com,self.n_gen)\n",
    "        else:\n",
    "            structure_constants = c\n",
    "        \n",
    "        \n",
    "        return structure_constants, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model = find_generators(n_dim,n_gen,n_com).to(device)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(type(param),param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three components to the loss function. Note $|G| = n_{gen}$.\n",
    "\n",
    " 1. ${\\bf Invariance }$\n",
    " $$\\mathcal{L}_{inv} = \\frac{a_{inv}}{ \\epsilon^2} \\sum_{j=1}^{n_{gen}} \\left\\{ \\sum_{i=1}^{N} \\left[ \\phi \\left[ (I+\\epsilon W_j) \\vec{x}_i \\right] - \\phi\\left(\\vec{x}_i \\right) \\right]^2 \\right\\}$$\n",
    "where we will use $\\phi \\equiv torch.norm$ here ($L^2$ norm which includes imaginary numbers), i.e.,\n",
    "$$ \\phi(\\vec{x}) = \\sqrt{\\sum_{i=1}^{n_{dim}} |x_i|^2}$$\n",
    "\n",
    "\n",
    " 2. ${\\bf Normalization}$\n",
    " $$\\mathcal{L}_{norm} = a_{norm}  \\sum_{i=1}^{n_{gen}} \\left[\\text{Tr}(W_i W_i^T) - 2\\right]^2$$\n",
    " Note that  $\\text{Tr}(W_i W_i^T)$ is equivalent to squaring all the elements of an array, or performing numpy multiplication of arrays in python.\n",
    " \n",
    " \n",
    " 3. ${\\bf Orthogonality}$\n",
    " $$\\mathcal{L}_{orth} = a_{orth}  \\sum_{i, j = 1, i<j}^{n_{gen}} \\text{Tr}(W_i W_j^T)^2$$ \n",
    "\n",
    "4. ${ \\bf Closure}$\n",
    " $$\\mathcal{L}_{clos} = a_{clos}  \\sum_{i, j = 1, i<j}^{n_{gen}} \\text{Tr}(C_{[ij]} C_{[ij]}^T)^2$$\n",
    " where\n",
    " $$C_{[ij]} = [W_i, W_j] - \\sum_{k=1}^{n_{gen}} a_{[ij]k} W_k$$\n",
    "\n",
    "and therefore, our loss becomes \n",
    "$$\\mathcal{L} = \\mathcal{L}_{inv} + \\mathcal{L}_{norm} + \\mathcal{L}_{orth} + \\mathcal{L}_{clos}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and choose optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(data,generators,struc_const,eps,ainv=1,anorm=1,aorth=1,aclos=1,components = False):\n",
    "    \n",
    "    lossi = 0.\n",
    "    lossn = 0.\n",
    "    losso = 0.\n",
    "    lossc = 0.\n",
    "    #lossspsc = 0.\n",
    "    #lossspg = 0.\n",
    "    comm_index = 0\n",
    "    \n",
    "    for i, G in enumerate(generators): \n",
    "        transform = torch.transpose((torch.eye(G.shape[0]) + eps*G)@torch.transpose(data,dim0=1,dim1=0), dim0=1,dim1=0 )\n",
    "        transform = transform.reshape(data.shape[0],data.shape[1])\n",
    "        \n",
    "        lossi  += torch.mean( ( oracle(transform) - oracle(data) )**2 ) / eps**2 \n",
    "        lossn  += (torch.sum(G**2) - 2)**2\n",
    "        \n",
    "        for j, H in enumerate(generators):\n",
    "            if i < j:\n",
    "                losso += torch.sum(G*H)**2\n",
    "                \n",
    "                if data.shape[1]<6:\n",
    "                    C1 = bracket(G,H)\n",
    "                    C2 = 0\n",
    "                    for k,K in enumerate(generators):\n",
    "                        C2 += struc_const[comm_index,k]*K\n",
    "                    C = C1 - C2\n",
    "                    lossc += torch.sum(C**2)**2\n",
    "                    comm_index +=1\n",
    "    \n",
    "    # attempt at adding a sparsity condition \n",
    "    # to both the generators and structure constants\n",
    "    # (Did not work well)\n",
    "    \n",
    "    #for i, G in enumerate(generators):\n",
    "    #    lossspg += len(torch.where(torch.abs(G)>1e-02)[0])\n",
    "        \n",
    "    #lossspsc = len(torch.where(torch.abs(struc_const)>1e-02)[0])\n",
    "    \n",
    "    if components:\n",
    "        return [ ainv*lossi,  anorm*lossn,  aorth*losso,  aclos*lossc ]\n",
    "\n",
    "    L = ainv*lossi + anorm*lossn + aorth*losso + aclos*lossc #+ lossspsc + lossspg\n",
    "    return  L\n",
    "\n",
    "lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(initial_matrices, initial_struc_const, data, model, loss_fn, epochs, optimizer, eps):\n",
    "    \n",
    "    history = {'train_loss': [],\n",
    "               'components_loss':[]} \n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    ainv = 1\n",
    "    anorm = 1\n",
    "    aorth = 1\n",
    "    if data.shape[1]<6:\n",
    "        aclos = 1\n",
    "    else:\n",
    "        aclos = 0\n",
    "    \n",
    "    X = initial_matrices\n",
    "    Y = initial_struc_const\n",
    "    size = X.shape[0]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        train_loss = 0.\n",
    "        model.train()\n",
    "        struc_const, gens = model(X,Y)\n",
    "        \n",
    "        loss = loss_fn( data         = data,\n",
    "                        generators   = gens,\n",
    "                        struc_const  = struc_const,\n",
    "                        eps          = eps,\n",
    "                        ainv         = ainv,\n",
    "                        anorm        = anorm,\n",
    "                        aorth        = aorth,\n",
    "                        aclos        = aclos ) #.mean()\n",
    "        \n",
    "        comp_loss = loss_fn( data         = data,\n",
    "                             generators   = gens,\n",
    "                             struc_const  = struc_const,\n",
    "                             eps          = eps,\n",
    "                             ainv         = ainv,\n",
    "                             anorm        = anorm,\n",
    "                             aorth        = aorth,\n",
    "                             aclos        = aclos,\n",
    "                             components   = True)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "        comp_loss_for_epoch = []\n",
    "        \n",
    "        for j in range(len(comp_loss)):\n",
    "            if torch.is_tensor(comp_loss[j]):\n",
    "                comp_loss_for_epoch.append(comp_loss[j].data.item())\n",
    "            else:\n",
    "                comp_loss_for_epoch.append(comp_loss[j])\n",
    "            \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['components_loss'].append(comp_loss_for_epoch)\n",
    "        \n",
    "        if i%1==0:\n",
    "            print(f\"Epoch {i+1}   |  Train Loss: {train_loss}\",end='\\r') #{train_loss:>8f}\n",
    "        if i==epochs-1:\n",
    "            print(f\"Epoch {i+1}   |  Train Loss: {train_loss}\")\n",
    "    \n",
    "        if train_loss*1e25 < 1:\n",
    "            print()\n",
    "            print('Reached Near Machine Zero')\n",
    "            break\n",
    "    \n",
    "    \n",
    "    end = time()\n",
    "    total_time = end-start\n",
    "    print(f'Total Time: {total_time:>.8f}')\n",
    "    print(\"Complete.\")\n",
    "    return {'history': history}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 773   |  Train Loss: 3.65214413602948e-1515\r"
     ]
    }
   ],
   "source": [
    "epochs =1000\n",
    "\n",
    "training = train( initial_matrices    = initialize_matrices, \n",
    "                  initial_struc_const = initialize_struc_const,\n",
    "                  data                = data,\n",
    "                  model               = model, \n",
    "                  loss_fn             = loss_fn,\n",
    "                  epochs              = epochs,\n",
    "                  optimizer           = optimizer,\n",
    "                  eps                 = eps  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the History of Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_gen>1:\n",
    "    train_loss = np.array(training['history']['train_loss'])\n",
    "    comp_loss = np.array(training['history']['components_loss'])\n",
    "else:\n",
    "    train_loss = np.array(training['history']['train_loss'])\n",
    "    comp_loss = np.empty( ( train_loss.shape[0],len(training['history']['components_loss']) ) )\n",
    "    for i,comp in enumerate(training['history']['components_loss']):\n",
    "        for j,term in enumerate(comp):\n",
    "            if torch.is_tensor(term) and term.requires_grad:\n",
    "                comp_loss[i,j] = term.detach().numpy()\n",
    "            else:\n",
    "                comp_loss[i,j] = term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=train_loss.shape[0]\n",
    "plt.figure(figsize=(6,4)) #, dpi=100)\n",
    "plt.plot( train_loss[:N], linewidth=1, linestyle='-',  color = 'r', label='Total')\n",
    "plt.plot(comp_loss[:N,0], linewidth=1, linestyle=':',  color='b',   label='Invariance')\n",
    "plt.plot(comp_loss[:N,1], linewidth=1, linestyle='--', color='g',   label='Normalization')\n",
    "plt.plot(comp_loss[:N,2], linewidth=1, linestyle='-.', color='magenta', label='Orthogonality')\n",
    "plt.plot(comp_loss[:N,3], linewidth=1, linestyle='-.', color='cyan', label='Closure')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Components of Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    struc_pred, gens_pred = model(initialize_matrices,initialize_struc_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Symmetry Vector Plot (for $n_{dim} = 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_dim<3:\n",
    "    def draw_vectors(M, oracle):\n",
    "        plt.figure(figsize=(4,3.25))   #, dpi=100)\n",
    "\n",
    "        # Makes the background contour:\n",
    "        x_grid, y_grid = np.meshgrid(np.linspace(-2,2,101), np.linspace(-2,2,101))\n",
    "   \n",
    "        grid_points = torch.tensor(np.stack([x_grid.flatten(), y_grid.flatten()], axis=1))\n",
    "        oracle_vals = oracle(grid_points).numpy().reshape(x_grid.shape)\n",
    "\n",
    "        plt.contourf(x_grid, y_grid, oracle_vals, 32, cmap='RdBu') #, norm = mpl.colors.CenteredNorm() )\n",
    "\n",
    "        # now make the vector field:\n",
    "        # This makes the points which are the tails of the vectors\n",
    "        x_grid, y_grid = np.meshgrid(np.linspace(-2,2,20), np.linspace(-2,2,20))\n",
    "\n",
    "        # calculates the vector at each point\n",
    "        x_vec_grid, y_vec_grid = np.einsum('il,ljk', M.detach().numpy(), np.stack([x_grid, y_grid]))\n",
    "       \n",
    "        # loops over those points and corresponding vectors and draws the arrow\n",
    "        for x, y, dx, dy in zip(x_grid.flatten(),\n",
    "                                y_grid.flatten(),\n",
    "                                x_vec_grid.flatten(),\n",
    "                                y_vec_grid.flatten()):\n",
    "       \n",
    "            # this is the factor by which all vectors are scaled down:\n",
    "            scale=.05\n",
    "            plt.arrow(x, y, dx*scale, dy*scale, head_width=.03, lw=.5, fc='k', ec='k')\n",
    "\n",
    "        plt.xlim(-2,2)\n",
    "        plt.ylim(-2,2)\n",
    "        plt.yticks(np.arange(-2,3))\n",
    "        plt.xlabel('$x^{(1)}$',fontsize=12)\n",
    "        plt.ylabel('$x^{(2)}$',fontsize=12)\n",
    "        plt.colorbar(label='$\\phi(\\\\vec{x})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of the generator you want to draw:\n",
    "if n_dim<3:\n",
    "    M = gens_pred[0]\n",
    "    # pass that matrix into the function along with the oracle function:\n",
    "    draw_vectors(M, oracle = oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Resulting Generator(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=1\n",
    "cols=3\n",
    "figsize=(12,2.5)\n",
    "\n",
    "# Create labels for matrix rows and columns\n",
    "ticks_gen_im =[]\n",
    "ticks_gen_im_label = []\n",
    "for i in range(n_dim):\n",
    "    ticks_gen_im.append(i)\n",
    "    ticks_gen_im_label.append(str(i+1))\n",
    "    \n",
    "if rows==1 and cols==1:\n",
    "    fig = plt.subplots(rows,cols,figsize=figsize)\n",
    "    GEN = gens_pred[0]\n",
    "    plt.subplot(111)\n",
    "    print(f'Generator: \\n {GEN} \\n')\n",
    "    im = plt.imshow(GEN.detach().numpy(), cmap='RdBu', vmin=-1., vmax=1.)#norm=mpl.colors.CenteredNorm())\n",
    "#     det = np.linalg.det(np.eye(GEN.shape[0]) + eps * GEN.detach().numpy())\n",
    "#     ax.set_title(f'det = {det}')\n",
    "#     ax.axis('off')\n",
    "    plt.xticks(ticks=ticks_gen_im, labels=ticks_gen_im_label)\n",
    "    plt.yticks(ticks=ticks_gen_im, labels=ticks_gen_im_label)\n",
    "    plt.title('Generator '+str(1),fontsize=20)\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "else:\n",
    "    fig,axes = plt.subplots(rows,cols,figsize=figsize)\n",
    "#     for i, ax_GEN in enumerate(zip(axes.flat,gens_pred)):\n",
    "#         plt.subplot(rows,cols,i+1)\n",
    "#         if n_gen<5:\n",
    "#             print(f'Generator {i+1}: \\n {ax_GEN[1]} \\n')\n",
    "#         im = ax_GEN[0].imshow(ax_GEN[1].detach().numpy(), cmap='RdBu', vmin=-1., vmax=1.)\n",
    "#         ax_GEN[0].set_xticks(ticks=ticks_gen_im)\n",
    "#         ax_GEN[0].set_xticklabels(labels=ticks_gen_im_label)\n",
    "#         ax_GEN[0].set_yticks(ticks=ticks_gen_im)\n",
    "#         ax_GEN[0].set_yticklabels(labels=ticks_gen_im_label)\n",
    "#         ax_GEN[0].set_title('Generator '+str(i+1),fontsize=20)\n",
    "    for i,GEN in enumerate(gens_pred):\n",
    "        plt.subplot(rows,cols,i+1)\n",
    "        if n_gen<10:\n",
    "            print(f'Generator {i+1}: \\n {GEN} \\n')\n",
    "        im = plt.imshow(GEN.detach().numpy(), cmap='RdBu', vmin=-1., vmax=1.) # use ax_GEN[0] with axes\n",
    "#         if n_gen<7:\n",
    "#             det = np.linalg.det(np.eye(GEN.shape[0]) + eps * GEN.detach().numpy()) #ax_GEN[1]\n",
    "#             plt.title(f'det = {det}')\n",
    "#         plt.axis('off')\n",
    "        plt.xticks(ticks=ticks_gen_im, labels=ticks_gen_im_label)\n",
    "        plt.yticks(ticks=ticks_gen_im, labels=ticks_gen_im_label)\n",
    "        plt.title('Generator '+str(i+1),fontsize=20)\n",
    "\n",
    "    plt.subplots_adjust(right=0.8)\n",
    "    plt.colorbar(im, ax=axes.ravel().tolist(), ticks = [-1.0,-0.75,-0.50,-0.25,0,0.25,0.50,0.75,1.0])\n",
    "#plt.savefig('Orth_gen_3_3_00.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Rotation Axis Results for  $n_{dim} = 3$, $n_{gen} = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from code by Alex Roman\n",
    "def draw_vec(ax, v, lw, color, label):\n",
    "    # Draw a vector to ax, this adds lines for the projection\n",
    "    # Draw vector (0,0,0) to (v0,v1,v2)\n",
    "    ax.plot([0,   v[0]], [0,   v[1]], [0, v[2]], color=color, lw=lw, label=label)\n",
    "    # Fix (x,y) and draw a line from z=0 to z=v[2] (z component of rot vec)\n",
    "    # Draw vector (v0,v1,0) to (v0,v1,v2) == straight line up... etc.\n",
    "    ax.plot([v[0],v[0]], [v[1],v[1]], [0,v[2]], color='b', alpha=.25, ls='--')\n",
    "    # Fix (x,z) and draw a line from y=0 to y=v[1] (y component of rot vec)\n",
    "    ax.plot([v[0],v[0]], [0   ,v[1]], [0,0   ], color='b', alpha=.25, ls='--')\n",
    "    # Fix (y,z) and draw a line from x=0 to x=v[0] (x component of rot vec)\n",
    "    ax.plot([0   ,v[0]], [v[1],v[1]], [0,0   ], color='b', alpha=.25, ls='--')\n",
    "    \n",
    "def get_axis_np(M):\n",
    "    # Finds the eigenvector with min(Imaginary(eigenvalue))\n",
    "    # if the matrix is a rotation matrix or a generator of rotations, then this vector is the axis of rotation \n",
    "    eig_vals, eig_vecs = np.linalg.eig(M)\n",
    "    index = np.argmin(np.sum(np.abs(eig_vecs.T.imag),axis=1)) # T is for transpose\n",
    "    # find the minimum arg of the minimum imaginary component\n",
    "    # pass that to the transposed eigenvector array to pull the eigenvecto\n",
    "    axis = eig_vecs.T[index].real\n",
    "    # Change to more positive than negative values in axis vector by multiplying by the net sign\n",
    "    return np.sign(np.sum(axis))*axis\n",
    "\n",
    "def draw_axes(gens, verbose=True):\n",
    "    G1, G2, G3 = gens\n",
    "    # gather rotation axes\n",
    "    axis1 = get_axis_np(G1.detach().numpy())\n",
    "    axis2 = get_axis_np(G2.detach().numpy())\n",
    "    axis3 = get_axis_np(G3.detach().numpy())\n",
    "    \n",
    "    # to be more verbose (include extra detail) list the \n",
    "    # rotation axes found from the axis function\n",
    "    if verbose:\n",
    "        print(f'Axis 1: {axis1}')\n",
    "        print(f'Axis 2: {axis2}')\n",
    "        print(f'Axis 3: {axis3}')\n",
    "    \n",
    "    # set up plot\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # draw x,y,z axes on graph\n",
    "    ax_lim = 1\n",
    "    ax.plot([-ax_lim,ax_lim],[0,0],[0,0], color='black', alpha=.3)\n",
    "    ax.plot([0,0],[-ax_lim,ax_lim],[0,0], color='black', alpha=.3)\n",
    "    ax.plot([0,0],[0,0],[-ax_lim,ax_lim], color='black', alpha=.3)\n",
    "\n",
    "    # set bounds on graph to be +-1\n",
    "    ax.set_xlim(-ax_lim,ax_lim)\n",
    "    ax.set_ylim(-ax_lim,ax_lim)\n",
    "    ax.set_zlim(-ax_lim,ax_lim)\n",
    "    \n",
    "    # draw each rotation axis\n",
    "    lw = 5\n",
    "    draw_vec(ax = ax, v = axis1, lw=lw, color = 'b', label='Axis '+str(1))\n",
    "    draw_vec(ax = ax, v = axis2, lw=lw, color = 'r', label='Axis '+str(2))\n",
    "    draw_vec(ax = ax, v = axis3, lw=lw, color = 'g', label='Axis '+str(3))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(gens_pred)==3 and n_dim==3:\n",
    "    draw_axes(gens_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Resulting Structure Constants (for $n_{gen}>1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_gen>1:\n",
    "    \n",
    "    figsize=(4,3)\n",
    "    \n",
    "    if n_gen==3:\n",
    "        X = torch.tensor(struc_pred.numpy())\n",
    "        struc_cyclic = X\n",
    "        struc_cyclic[1] = -X[1]\n",
    "        \n",
    "    commutator_labels = []\n",
    "    if n_com==3:\n",
    "        # Make the commutations cyclic for 3 generators\n",
    "        for i in range(n_gen):\n",
    "             for j in range(n_gen):\n",
    "                    if i<j:\n",
    "                        if (j-i)==2:\n",
    "                            commutator_labels.append(str(j+1)+str(i+1))\n",
    "                        else:\n",
    "                            commutator_labels.append(str(i+1)+str(j+1))\n",
    "    else:\n",
    "        for i in range(n_gen):\n",
    "            for j in range(n_gen):\n",
    "                if i<j:\n",
    "                    commutator_labels.append(str(i+1)+str(j+1))\n",
    "        \n",
    "    ticks_com = []\n",
    "    for i in range(n_com):\n",
    "        ticks_com.append(i)\n",
    "\n",
    "    ticks_gen = []\n",
    "    generator_labels = []\n",
    "    for i in range(n_gen):\n",
    "        ticks_gen.append(i)\n",
    "        generator_labels.append(str(i+1))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    if n_com==3:\n",
    "        plt.imshow(struc_cyclic.detach().numpy(), cmap='RdBu', vmin=-1.,vmax=1.)#norm=mpl.colors.CenteredNorm())\n",
    "    else:\n",
    "        plt.imshow(struc_pred.detach().numpy(), cmap='RdBu', vmin=-1.,vmax=1.)#norm=mpl.colors.CenteredNorm())\n",
    "    plt.xticks(ticks=ticks_gen,labels=generator_labels)\n",
    "    plt.xlabel('Generator',fontsize=15)\n",
    "    plt.yticks(ticks=ticks_com,labels=commutator_labels)\n",
    "    plt.ylabel('Bracket',fontsize=15)\n",
    "    plt.title('Structure Constants',fontsize=15)\n",
    "    plt.colorbar()\n",
    "    plt.savefig('Orth_sc_3_3_00.png',bbox_inches='tight')\n",
    "    \n",
    "#     # add grid lines\n",
    "#     for i in range(n_gen-1):\n",
    "#         plt.axvline(x=1/2+i, linewidth=1, color ='black')\n",
    "#     for i in range(n_com-1):\n",
    "#         plt.axhline(y=1/2+i-0.01, linewidth=1, color ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the Structure Constants Produce an Algebra (for $n_{gen}>1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: \n",
      " Structure Constants = [0.017815 -0.023160 0.984890]\n",
      " \n",
      " C = \n",
      "  [[-0.000317 0.026862 -0.014158]\n",
      " [-0.027634 0.000832 -0.011666]\n",
      " [0.014358 0.011576 0.000459]] \n",
      "\n",
      "The structure constants were found successfully with a mean absolute error (MAE) of 0.011984755043286244. \n",
      " \n",
      "\n",
      "31: \n",
      " Structure Constants = [-0.003899 1.009901 0.025461]\n",
      " \n",
      " C = \n",
      "  [[0.000270 -0.008417 0.013760]\n",
      " [0.007870 0.000831 0.021938]\n",
      " [-0.014479 -0.022601 -0.000074]] \n",
      "\n",
      "The structure constants were found successfully with a mean absolute error (MAE) of 0.010026740119474126. \n",
      " \n",
      "\n",
      "23: \n",
      " Structure Constants = [1.017229 -0.007850 -0.024331]\n",
      " \n",
      " C = \n",
      "  [[0.000338 0.018127 -0.004934]\n",
      " [-0.018334 0.000939 -0.024371]\n",
      " [0.005708 0.024127 -0.000293]] \n",
      "\n",
      "The structure constants were found successfully with a mean absolute error (MAE) of 0.010796919305456357. \n",
      " \n",
      "\n",
      "Total MAE = 0.03280841446821672\n"
     ]
    }
   ],
   "source": [
    "if n_gen>1:\n",
    "    if n_gen==3:\n",
    "        X = torch.tensor(struc_pred.numpy())\n",
    "        struc_cyclic = X\n",
    "        struc_cyclic[1] = -X[1]\n",
    "\n",
    "    comm_index = 0\n",
    "    Cs = []\n",
    "    for i,G in enumerate(gens_pred):\n",
    "        for j,H in enumerate(gens_pred):\n",
    "            if i<j and n_gen!=3:\n",
    "                C1 = bracket(G,H)\n",
    "                C2 = 0\n",
    "                for k,K in enumerate(gens_pred):\n",
    "                    C2 += struc_pred[comm_index,k]*K\n",
    "                C = C1 - C2\n",
    "                error = torch.mean(torch.abs(C.real))\n",
    "                print(str(i+1)+str(j+1)+': \\n Structure Constants = '+str(struc_pred[comm_index,:].detach().numpy())+'\\n \\n C = \\n ',C.detach().numpy(),'\\n')\n",
    "                if error<1e-1:\n",
    "                    print(f'The structure constants were found successfully with a mean absolute error (MAE) of {error}. \\n \\n')\n",
    "                elif error>1e-1:\n",
    "                    print(f'The structure constants were NOT found successfully with a mean absolute error (MAE) of {error}. \\n \\n')\n",
    "                Cs.append(C)\n",
    "                comm_index+=1\n",
    "            # Make the cyclic commutators if n_gen = 3   \n",
    "            elif i<j and n_gen==3:\n",
    "                if (j-i)==2:\n",
    "                    C1 = bracket(H,G)\n",
    "                    C2 = 0\n",
    "                    for k,K in enumerate(gens_pred):\n",
    "                        C2 += struc_cyclic[comm_index,k]*K\n",
    "                    C = C1 - C2\n",
    "                    error = torch.mean(torch.abs(C.real))\n",
    "                    print(str(j+1)+str(i+1)+': \\n Structure Constants = '+str(struc_cyclic[comm_index,:].detach().numpy())+'\\n \\n C = \\n ',C.detach().numpy(),'\\n')\n",
    "                    if error<1e-1:\n",
    "                        print(f'The structure constants were found successfully with a mean absolute error (MAE) of {error}. \\n \\n')\n",
    "                    elif error>1e-1:\n",
    "                        print(f'The structure constants were NOT found successfully with a mean absolute error (MAE) of {error}. \\n \\n') \n",
    "                    Cs.append(C)\n",
    "                    comm_index+=1\n",
    "                else:\n",
    "                    C1 = bracket(G,H)\n",
    "                    C2 = 0\n",
    "                    for k,K in enumerate(gens_pred):\n",
    "                        C2 += struc_cyclic[comm_index,k]*K\n",
    "                    C = C1 - C2\n",
    "                    error = torch.mean(torch.abs(C.real))\n",
    "                    print(str(i+1)+str(j+1)+': \\n Structure Constants = '+str(struc_cyclic[comm_index,:].detach().numpy())+'\\n \\n C = \\n ',C.detach().numpy(),'\\n')\n",
    "                    if error<1e-1:\n",
    "                        print(f'The structure constants were found successfully with a mean absolute error (MAE) of {error}. \\n \\n')\n",
    "                    elif error>1e-1:\n",
    "                        print(f'The structure constants were NOT found successfully with a mean absolute error (MAE) of {error}. \\n \\n') \n",
    "                    Cs.append(C)\n",
    "                    comm_index+=1\n",
    "    \n",
    "    \n",
    "    # Calculate the total MSE in finding the structure constants\n",
    "    tot_error = 0.\n",
    "    for i,C in enumerate(Cs):\n",
    "        tot_error+=torch.mean(torch.abs(C.real))\n",
    "    print(f'Total MAE = {tot_error}')\n",
    "    # if error < 1e-1:\n",
    "    #     print(f'The structure constants were found successfully with a mean absolute error (MAE) of {error}.')\n",
    "    # else:\n",
    "    #     print(f'The structure constants were NOT found successfully with a mean absolute error (MAE) of {error}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Orthogonality (for $n_{gen}>1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(v, w):\n",
    "    # Angle between vectors\n",
    "    return v @ w / (torch.norm(v) * torch.norm(w))\n",
    "\n",
    "def get_axis(M):\n",
    "    # Finds the eigenvector with min(Imaginary(eigenvalue))\n",
    "    # if the matrix is a rotation matrix or a generator of rotation,s then this vector is the axis of rotation  \n",
    "    eig_vals, eig_vecs = torch.linalg.eig(M)\n",
    "    # find the minimum arg of the minimum imaginary component\n",
    "    # pass that to the transposed eigenvector array to pull the eigenvector\n",
    "    axis = eig_vecs.T[torch.argmin(torch.abs(eig_vals.imag))]\n",
    "    # Change to more positive than negative values in axis vector by multiplying by the net sign\n",
    "    return torch.sign(torch.sum(axis).real)*axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between generator 1 and 2: -0.0000264038 rad, 90.0015128290 deg\n",
      "Angle between generator 1 and 3: 0.0000114697 rad, 89.9993428343 deg\n",
      "Angle between generator 2 and 3: -0.0000225576 rad, 90.0012924545 deg\n"
     ]
    }
   ],
   "source": [
    "for i,G in enumerate(gens_pred):\n",
    "    for j,H in enumerate(gens_pred):\n",
    "        if i<j:\n",
    "            angle = get_angle(get_axis(G).real, get_axis(H).real)\n",
    "            angle_deg = 180/np.pi*np.arccos(float(get_angle(get_axis(G).real, get_axis(H).real)))\n",
    "            print(f'Angle between generator {i+1} and {j+1}: {angle:>.10f} rad, {angle_deg:>.10f} deg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
